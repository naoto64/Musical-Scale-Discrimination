<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>リアルタイム音階解析</title>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        #pitch { font-size: 2em; font-weight: bold; margin-top: 20px; }
        #chords { font-size: 1.5em; color: blue; }
    </style>
</head>
<body>
    <h1>リアルタイム音階解析</h1>
    <button onclick="startAudio()">録音開始</button>
    <div id="pitch">音階: なし</div>
    <div id="chords">和音: なし</div>

    <script>
        let audioContext, analyser, microphone, bufferLength, timeDomainData, frequencyData;

        async function startAudio() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 4096;  
            analyser.smoothingTimeConstant = 0.3;
            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);

            bufferLength = analyser.fftSize;
            timeDomainData = new Float32Array(bufferLength);
            frequencyData = new Uint8Array(analyser.frequencyBinCount);

            detectPitch();
        }

        function detectPitch() {
            analyser.getFloatTimeDomainData(timeDomainData);
            analyser.getByteFrequencyData(frequencyData);

            let fundamentalFreq = autoCorrelate(timeDomainData, audioContext.sampleRate);
            if (!fundamentalFreq) {
                fundamentalFreq = findStrongestPeak(frequencyData);
            }

            let mainNote = getNoteFromFrequency(fundamentalFreq);
            let chordNotes = findChordNotes(frequencyData, fundamentalFreq);

            document.getElementById("pitch").textContent = `音階: ${mainNote || "なし"}`;
            document.getElementById("chords").textContent = `和音: ${chordNotes.length > 0 ? chordNotes.join(" - ") : "なし"}`;

            requestAnimationFrame(detectPitch);
        }

        function autoCorrelate(buffer, sampleRate) {
            let size = buffer.length;
            let bestOffset = -1;
            let bestCorrelation = 0;
            let rms = 0;
            let correlations = new Array(size);

            for (let i = 0; i < size; i++) {
                let val = buffer[i];
                rms += val * val;
            }
            rms = Math.sqrt(rms / size);
            if (rms < 0.01) return null;

            let maxLag = size / 2;
            for (let lag = 0; lag < maxLag; lag++) {
                let correlation = 0;
                for (let i = 0; i < maxLag; i++) {
                    correlation += buffer[i] * buffer[i + lag];
                }
                correlation /= maxLag;
                correlations[lag] = correlation;

                if (correlation > bestCorrelation) {
                    bestCorrelation = correlation;
                    bestOffset = lag;
                }
            }

            if (bestOffset === -1 || bestCorrelation < 0.7) return null;
            return sampleRate / bestOffset;
        }

        function findStrongestPeak(frequencyData) {
            let maxIndex = 0;
            let maxAmplitude = 0;

            for (let i = 1; i < frequencyData.length - 1; i++) {
                if (frequencyData[i] > maxAmplitude) {
                    maxAmplitude = frequencyData[i];
                    maxIndex = i;
                }
            }

            if (maxAmplitude < 30) return null;
            return (maxIndex * audioContext.sampleRate) / analyser.fftSize;
        }

        function findChordNotes(frequencyData, mainFreq) {
            let detectedNotes = [];
            let peakFrequencies = [];
            let maxAmplitude = Math.max(...frequencyData);
            let threshold = maxAmplitude * 0.6;

            for (let i = 1; i < frequencyData.length - 1; i++) {
                if (frequencyData[i] > threshold &&
                    frequencyData[i] > frequencyData[i - 1] &&
                    frequencyData[i] > frequencyData[i + 1]) {
                    let freq = (i * audioContext.sampleRate) / analyser.fftSize;
                    if (freq > 60 && freq < 5000) {
                        peakFrequencies.push(freq);
                    }
                }
            }

            peakFrequencies.forEach(freq => {
                let note = getNoteFromFrequency(freq);
                if (note && !detectedNotes.includes(note) && Math.abs(freq - mainFreq) > 10) {
                    detectedNotes.push(note);
                }
            });

            return detectedNotes.slice(0, 4);
        }

        function getNoteFromFrequency(freq) {
            if (!freq) return null;

            const noteNames = ["ラ", "ラ#", "シ", "ド", "ド#", "レ", "レ#", "ミ", "ファ", "ファ#", "ソ", "ソ#"];
            let A4 = 440;
            let semitone = 12 * Math.log2(freq / A4);
            let noteIndex = Math.round(semitone) % 12;

            return noteNames[(noteIndex + 12) % 12];
        }
    </script>
</body>
</html>
